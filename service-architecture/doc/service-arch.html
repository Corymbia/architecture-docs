<html>

<h2>Eucalyptus Service Architecture</h2>

Eucalyptus is organized a tiered ensemble of web services.  This missive
outlines the organization of these services and the messaging 
interaction that takes place between these services in
response to user requests.
<p>
To begin with, it is important to understand that difference between a service
and a container within the Eucalyptus architecture.  At its core,
Eucalyptus uses an
<a href="http://en.wikipedia.org/wiki/Enterprise_service_bus">
Enterprise Service Bus</a> model as the basis for its architecture.  Service
components "plug into" a universal naming and messaging software substrate
that separates (abstracts away) communication and location functions
throughout the ensemble.  As a result, all services "see" a common framework
that handles secure message routing and delivery, regardless of physical
location.

<h2>Enterprise Service Bus and Eucalyptus Service Components</h2>

The service bus is implemented as a logical communication channel between web
service containers that are, in turn, run by web servers.  The web service
containers take care of message intergrity, security, and dispatch and the web
servers take care of manageing the container lifecycle (starting a container,
stopping a container, etc.)
<p>
Thus, at a high level, the message flow between <i>any</i> two internal
Eucayptus services that are located on separate machines is
<ul>
<li> the sending service components puts the message on the Enterprise Bus
<li> the Enterprise Bus calls the web service stack to implement the
communication
<li> the web service stack uses the web server to connect to the network and
send the message to another web server
<li> the receiving web server hands the message to the receiving web 
service stack
<li> the receiving stack puts the message on the Enterprise Bus
<li> the receiving service gets the message from the Enterprise Bus
</ul>
However, if the services are located on the same machine they work in exactly
same way (they do not need to be specialized for local and remote
communication) because of the bus.  Indeed, the implementation of the
Enterprise bus short-cuts the message path to bypass the web service stack and
to deliver the message directly when two services are co-located and they are
both written in Java.  For this
reason, services that are running on the same physical machine run in the 
same Java virtual machine.  If the services are written in different languages
(C and Java, for example) then they must use the full stack and communicate
using local Linux networking via sockets.
<p>
Note that this model is asynchronous which means that all service components
must supply a "call back" handler for the bus to call when a message is to be
delivered.  All Eucalyptus software components, fundamentally, use this
bus-style architecture to communicate.  That is, regardless of the service,
the Eucalyptus code that implements the service interfaces to the bus, both to
send messages to other components, and to receive messages via call backs, and
the bus and the web service software take care of securely transmitting the
information in a single, uniform way.

<h2>Major Eucalyptus Service Components</h2>

Eucalyptus consists of 7 major service components:
<ul>
<li><b>The Cloud Controller (CLC)</b> -- The CLC implements request processing
for all AWS EC2 requests.  It also coordinates the Eucalyptus secure 
bootstrapping and component registartion protocol.
<li><b>EUARE</b> -- The EUARE service implements the Eucalyptus identity
management system.  EUARE is compatible with the AWS Identity Access
Management (IAM) API.  It also includes extensions specifically added for
enterprise clouds such as resource quotas.
<li><b>Walrus</b> -- Walrus implements object storage for Eucalyptus.  It is
interface compatible with the AWS Simple Storage Service (S3).
<li><b>The Cluster Controller (CC)</b> -- The CC implements the
Eucalyptus-internal software defined networking subsystem that virtualizes the
network used by virtual machines (VMs) that are 
hosted within the Eucalyptus cloud.  It also
implements VM scheduling for a partition of the compute resources (often
termed a "cluster") within the overall Eucalyptus cloud.
<li><b>The VMWare Broker</b> -- The VMWare broker acts as a gateway between
the CC and VMWare virtualization components and services.  
It exports the same
Eucalyptus-internal API as the Node Controller so that the CC can operate
either without including specialized functionality for either.
<li><b>The Storage Controller (SC)</b> -- The SC implements the Eucalyptus
Block Storage (EBS) protocol.  EBS is compatible with the AWS Elastic Block
Store API, allowing virtual machines to attach block storage devices through
the cloud network.
<li><b>The Node Controller (NC)</b> -- The NC actuates virtual machines on
Linux machines that support an open source hypervisor.  It creates a bootable
instance from an image (stored in Walrus), configures the software defined
network, and attaches any block devices that the user requests.
</ul>
<p>
<img src=arch.png width=1000>
<p>
The Figure depicts the 7 Eucalyptus top level components and their messaging
relationships.  Each blue arrow indicates a message request from the requester
to the target.  The green arrows show which componets have access to a
distributed shared database service that is used to implement state
persistence (discussed below). 

<h3>The Eucalyptus Front End</h3>

Requests from users or the cloud administrators (left side of
the figure) are delivered
to the CLC, EUARE, or Walrus, depending on the specific call.  These
services collectively form the Eucalyptus "front end" or "top tier"
of a deployment.  The Eucalyptus
web service stack (not shown in the figure) takes care of message dispatch to
the appropriate service within the front end.  Walrus uses a <a
href="http://en.wikipedia.org/wiki/Category:Linux_file_systems">Linux file
system</a> as a storage medium for the objects it manages (depicted as an
inverted triangle in the figure).

<h3>The Eucalyptus Middle End</h3>

The CC, VMWare Broker, and SC compose the "middle end" or "middle tier" of a
Eucalyptus deployment.  The CLC sends VM provisioning commands to the CC and
block storage volume commands to the SC.  The CC communicates with the VMWare
Broker to actuate virtualization commands.  The CC also interacts with Linux
to implement Eucalyptus' software defined networking abstractions.  It manages
<a href="http://en.wikipedia.org/wiki/Iptables">Linux iptables rules</a>
to implement firewalls and address translation, 
<a href="http://linux-ip.net/html/routing-tables.html">Linux routing
tables</a> entries, a <a
href="http://www.yolinux.com/TUTORIALS/DHCP-Server.html">Linux DHCP
server</a>, and <a
href="http://www.techrepublic.com/article/linux-101-use-ifconfig-in-linux-to-configure-your-network/6040932">Linux
network interface state</a> by "shelling out" to a Linux system that will act
as a software router (typically the machine hosting the CC).  These
interactions with infrastructure outside of Eucalyptus (Linux and VMWare) are
depicted as inverted triangles in the figure. 
<p>
The SC sends snapshot storage requests to Walrus as snapshots are stored as
objects in Eucalyptus.

<h3>The Eucalyptus Back End</h3>

The back end of a Eucalyptus deployment is composed of Node Controllers (NCs).
Each host that uses a Linux system as a controlling domain (e.g. each host
running either a <a href="http://www.xen.org">Xen</a> or <a
href="http://www.linux-kvm.org/page/Main_Page">KVM</a> hypervisor) must host
an NC service.  The NC fields requests from the CC for VM, network, and block
storage acuation.  It requests images from Walrus, and sends volume attach and
detach requests to the SC.  The NC also interacts with the Linux system
hosting it via "shell outs" to implement instance caching.  These local Linux
interactions are depicted as inverted triangles in the figure.  

<h2>State Persistence</h2>

Eucalyptus is crash consistent which means that if any service is stopped due
to machine crash, software failure, network failure, etc. any internal state
necessary to allow the service to continue once it is able to run again is
persisted in a database (shown within the green circle in the figure).
Currently, all components have access to this distributed database service
except the CC and NC.  The CC is stateless, and the NC uses a local Linux file
to store a small amount of state associated with implementing a local instance
cache.  
<p>
To prevent the database from becoming a performance bottleneck, Eucalyptus
implements a two-level caching system.  All components using the database
service use <a
href="http://en.wikipedia.org/wiki/Hibernate_(Java)">Hibernate</a> to map
their Java objects to a relational database representation.  These objects are
stored in memory, but committed to the database (under Eucalyptus control) so
as to ensure causal consistency.  To further insulate Eucalyptus from the
potential of database congestion, objects are also stored 
<a href="http://docs.jboss.com/jbcache/1.2.4/TreeCache/html">Tree Cache</a> --
a component of <a href="http://www.jboss.org">JBOSS</a>.  Tree Cache
implements a distributed and replicated transactional object cache.  Thus an
object is replicated in memory across Java vitual machines as it is sent to
the database.
<p>
In addition to providing fast persistence to support crash consistency, this
persistence architecture is the basis of primary-backup High Availability (HA)
for the Eucalyptus platform itself.  The object persistence service (accessed
via a Eucalyptus-internal API) can be configured to use two separate database
installations as a synchronized backing store.  To determine which database is 
the currently active primary as well as to trigger a resynchronization after
database or network failure, the persistence stack uses <a
href="http://www.jgroups.org">Jgroups</a> to determine active component group
membership.

<h2>The Java Web Service Stack</h2>

The following figure shows the Java web service stack.  
<p>
<img src=ws-stack.png width=1000>
<p>
Elements depicted in blue are Eucalyptus specific.  Elements shown in red are
implemented in conjunction with an existing
open source technology (shown in parentheses).  All Java
services within Eucalyptus use the functionality implemented by this stack.  
<p>
Note that while the data persistence service is built into the stack itself,
and hence is available to all Java components, the persistence layer <i><b>is
not</b></i> used as a communication medium.  That is, while each 
Eucalyptus service component written in Java has access to the distributed
object cache, they each use it individually for data persistence and not to
communicate data between services.  Messages between services carry all
necessary state instead.  This architectural decision makes it possible to
use different language technologies to implement future services (or service
replacements).  That is, a Eucalyptus service does not need to be able to
access Java objects in the persistence layer in order to be part of the 
overall system.

<h2>Control Path and Data Path</h2>

With one exception, the Eucalyptus service components are part of a control
plane and not in the the data path for cloud allocations.  The one exception
is that Walrus performs the image decryption step of the AWS AMI protocol for
an uncached image.  Thus each Eucalyptus service "actuates" the underlying
hardware and software infrastructure but does not, itself, participate in the
user's interaction with the resources that have been allocated. 
<p>
There are two implementation features of Eucalyptus, however that appear not
to conform to this design principle and as such, bear some clarification.
<p>
<h3>Firewalls, NATs, and the CC</h3>

The first concerns the implementation of software defined networking that
Eucalyptus supports.  For each VM in a security group, Eucalyptus must
provision a virtual network that is isolated at both layers 2 and 3.
This isolation is implemented by
<ul>
<li> attaching a VM to a Linux bridge that has been configured to use a VLAN
that is unique to the security group in which it runs
<li> ensuring that all VMs within a security group are on the same layer 3
subnetwork
<li> making the default route for the VMs in a security group route to a Linux
machines that Eucalyptus can use as a firewall and to implement network
address translation (NAT).
</ul>
Currently, the CC uses the Linux machine that is hosting it to implement the
firewall and NAT using iptables.  
Thus all network traffic that is between a VM and an IP
address outside of its security group traverses the firewall which is
controlled by the CC.  However the result is that the machine that is hosting
the CC is in the data path for non-internal security group IP traffic.
<p>
The Linux machine hosting the CC also implements the NAT for each VM.  Under
the AWS networking semantics, each VM receives a "private" IP and a "public"
IP.  the private IP is assigned to the VM's network interface and the public
IP is installed as a NAT in the data path between the VM and the publicly
routed network.  Eucalyptus implements this NAT on the Linux machine that acts
as a firewall (the Linux machine hosting the CC).

<h3>Implementing EBS using a Linux Host as the Storage Server</h3>

The other scenario in which a Linux machine hosting a Eucalyptus component is
potentially in the data path occurs when Eucalyptus is configured to use a
Linux host as the block storage server for EBS.  Eucalyptus supports a number
of different configurations for EBS using devices that can export iSCSI
targets.  The default configuration uses <a
href="http://stgt.sourceforge.net">Linux tgt</a> on the machine hosting the SC
to export an iSCSI target and then the <a
href="http://en.wikipedia.org/wiki/Logical_Volume_Manager_(Linux)">Linux
Logical Volume Manager</a> and <a
href="http://en.wikipedia.org/wiki/Loop_device">Linux loop devices</a> to
provide file-backed volumes.  In this default configuration of Eucalyptus,
the SC commands the Linux machine hosting it to allocate and configure these
native Linux facilities.
<p>
While both the CC and the SC may rely on the "local" Linux host to implement
some functionality, neither the CC nor SC process itself is in the data path.
For example, once the CC installs iptables rules on the Linux machine hosting
it, the network traffic is handled by the Linux network stack without the CC
process in the data path.  Thus the CC and SC are true "controllers" and are
part of the control plane even when the machine that
hosts them is in the data path.

<h2>Request Processing</h2>

Eucalyptus services conform to a common three-stage architecture for request 
processing.
<p>
<img src=service-message.png width=1000>
<p>
The request processing stage authorizes each request using 
<a href="http://en.wikipedia.org/wiki/Public-key_infrastructure">
PKI</a> certificates.  Certificate management (creation, deletion, etc.) is
implemented by a service component within the CLC (not shown in the 
architecture figure).
This service stores the necessary user credential information securely using 
the persistent object service.
<p>
Once a request is authorized, the validity of the request (syntax and
semantics) are checked.  If the formation of the request is correct, it is
forwarded to a reservation subsystem where any necessary
capacity accounting is
performed.  The request is also sent to the state management stage where it is
logged "fulfilled."  The specific request is
essentially fulfilled (even though the outcome may only be to be able to tell
the user that the request is acknowledged and is pending) because Eucalyptus
has taken responsibility for tracking the lifecycle of the outcome at this
stage.   
<p>
Note that the AWS API (and indeed all popular IaaS API) make this
differentiation.  Specifically, a request itself is distinct from the outcome
it is requesting.  For example, a request to launch a VM is fulfilled when
Eucalyptus takes responsibility for attempting to launch the VM.  The user can
then be informed that her launch request is "done."  The VM launch itself
happens asynchronously and a seaparte request must be issued by the user
to determine when the launch is complete.  This request too is fulfilled when
Eucalyptus can report the status and does not block waiting for the launch to
finish.  Thus, an individual request (launch or status, in this case) is
fulfilled even while the outcome (a VM launch) itself is pending.  
<p>
From the reservation stage, a success code is sent to the user indicating that
the request has been accepted by Eucalyptus and any information that
accompanies a response is returned.  Resource allocation is asynchronous.  If
the request is to allocate or to modify the allocation of a resource, then the
request is forwaded to the "in progress" stage.
<p>
Here, Eucalyptus records that a request will be issued to an external
component for resource management, the response for which will be received
asynchronously.  Thus Eucalyptus marks an object as "in progress" and issues a
request to a resource allocation thread in the third stage to begin the
allocation request.
<p>
The resource allocation component makes an allocation request to the
resource (e.g. sends a message to another Eucalyptus process,
an external resource manager like VMWare, or 
issues a Linux command).  Again, the effect of the request or command is
determined asynchronously.  The third stage polls the resource for status and
updates an internal resource state object.  Once the entire request has been
fulfilled or has been determined to have failed, the resource update stage
contacts the resource allocation stage to indicate completion.  Resource
allocation notifies "in progress" of the status, and the request moves to
"fulfilled" to indicate that Eucalyptus has either performed the allocation
request, or that it has failed definitively.  If and when a subsequent 
request for status or termination arrives, the appropriate status will be
returned to the user. 
<p>
Internally, the stages use the enterprise service bus to communicate.
As such, asynchronous communication is implemented via callbacks.  
Externally, services
poll for "ground truth."  That is, each service assumes that its internal data
models the state of a request, but that state can become "stale" at any
moment.  Thus, the service polls its external "resource" periodically to
resynchronize the data model.  This information synchronization methodology
obviates the need to implement reliable call backs, which is difficult to
implement in a crash consistent manner.



</html>
